{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-28T11:42:02.247866Z",
     "start_time": "2024-03-28T11:41:59.184611Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba\n",
    "import nltk\n",
    "import spacy\n",
    "import json\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 文件导入\n",
    "    -   读取csv文件\n",
    "    -   转换csv为列表list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "datapath = 'data/test-f.csv'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T11:42:02.250545Z",
     "start_time": "2024-03-28T11:42:02.249009Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "data = pd.read_csv(datapath,index_col=0)\n",
    "data_records = data.to_dict('records')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T11:42:02.276960Z",
     "start_time": "2024-03-28T11:42:02.251492Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "sample_string = data_records[42]['content']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T11:42:02.277118Z",
     "start_time": "2024-03-28T11:42:02.274514Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 分词函数"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def cut_sentence(sent):\n",
    "    \"\"\"\n",
    "    :param sent: str\n",
    "    :return:  list\n",
    "\n",
    "    Write your own code here\n",
    "    \"\"\"\n",
    "    return list(jieba.cut(sent))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T11:42:02.279424Z",
     "start_time": "2024-03-28T11:42:02.278132Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 测试一下函数"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/c_/f8ygdlpx3nn0nxjx71cjbdkw0000gn/T/jieba.cache\n",
      "Loading model cost 0.307 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": "['有些', '事越', '想要', '越', '得不到', '，', '有些', '梦', '只能', '相信', '，', '是', '这样', '吗']"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_sentence(sample_string)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T11:42:02.591833Z",
     "start_time": "2024-03-28T11:42:02.280162Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 获取停用词"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def get_stopwords():\n",
    "    \"\"\"\n",
    "    You can provide A better list, here is an example.\n",
    "    https://github.com/goto456/stopwords\n",
    "    \"\"\"\n",
    "    stopwords = [word.strip() for word in open('data/cn_stopwords.txt').readlines()]\n",
    "    return stopwords\n",
    "stop_words = get_stopwords()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T11:42:02.594868Z",
     "start_time": "2024-03-28T11:42:02.592185Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 过滤停用词的函数"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "def strip_stopwords(words,stopwords):\n",
    "    \"\"\"\n",
    "    :param words:  词语列表\n",
    "    :param stopwords:   停用词列表\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return [word for word in words if word not in stopwords]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T04:48:24.300144Z",
     "start_time": "2024-03-31T04:48:24.296826Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 测试一下"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "['事越', '想要', '越', '得不到', '梦', '只能', '相信']"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strip_stopwords(cut_sentence(sample_string),stop_words)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T11:42:02.600231Z",
     "start_time": "2024-03-28T11:42:02.597966Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 遍历所有数据：分词 -> 过滤停用词"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Now loop over all sentences to get their words,\n",
    "then save the results to the variable data_records for later call.\n",
    "\n",
    "在这个函数里实现遍历所有数据 并分词\n",
    "\"\"\"\n",
    "def process_content(data_records):\n",
    "    \"\"\"\n",
    "    Your code here....\n",
    "    :return: list\n",
    "    \"\"\"\n",
    "    records = []\n",
    "\n",
    "    for item in data_records:\n",
    "        item.update({\n",
    "            'words':strip_stopwords(cut_sentence(str(item['content'])),stop_words)\n",
    "        })\n",
    "        records.append(item)\n",
    "    return records\n",
    "\n",
    "recordsWithWords = process_content(data_records)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T11:42:03.419845Z",
     "start_time": "2024-03-28T11:42:02.624800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 获取词典"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['宿舍', '要民汉合宿', '毛', '大三', '折腾', '早上', '竟然', '变成', '一个', '无理取闹', '…', '…', '多年', '周天', '先生', '率', '智多星', '律师', '策划师', '团队']\n"
     ]
    }
   ],
   "source": [
    "wordCorpus = []\n",
    "for item in recordsWithWords:\n",
    "    wordCorpus+=item['words']\n",
    "print(wordCorpus[:20])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T11:42:03.425110Z",
     "start_time": "2024-03-28T11:42:03.421430Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 这个函数实现了对词语列表的过滤 并存储"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# construct the vocabulary list\n",
    "\n",
    "def construct_vocab(wordCorpus,save=True):\n",
    "    \"\"\"\n",
    "    :param word_list:list\n",
    "    :return: a vocab set\n",
    "    [Attention]: A set means there is no repeat item.\n",
    "    \"\"\"\n",
    "\n",
    "    #Your code here..\n",
    "    vocab = list(set(wordCorpus))\n",
    "\n",
    "\n",
    "    ## You don't have to modify the following code\n",
    "    if save:\n",
    "        res = vocab\n",
    "        res.sort()\n",
    "        json.dump(res,open('results/vocab.json','w'),ensure_ascii=False)\n",
    "    return vocab\n",
    "vocab = construct_vocab(wordCorpus)\n",
    "word2id = { w:idx for idx,w in enumerate(vocab)}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T11:42:03.459613Z",
     "start_time": "2024-03-28T11:42:03.424902Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 这个函数获取词语列表的词频统计"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def wordFreq(wordList):\n",
    "    return dict(Counter(wordList))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T11:42:03.461689Z",
     "start_time": "2024-03-28T11:42:03.444182Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "vocabFreq = { w:0 for idx,w in enumerate(vocab)}\n",
    "wordCounted = wordFreq(wordCorpus)\n",
    "vocabFreq.update(wordCounted)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T11:42:03.461861Z",
     "start_time": "2024-03-28T11:42:03.459835Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# def get_total_freq_of_sentence(wordList,Freq):\n",
    "#     total = sum([Freq[word] for word in wordList])\n",
    "#     return total\n",
    "\n",
    "def convert_words2freqs(wordList,Freq):\n",
    "    \"\"\"\n",
    "    这个函数获取了词语列表中 每一个词的词频\n",
    "    :param wordList:\n",
    "    :param Freq: 字典 从wordFreq获取\n",
    "    :return: 列表，对应每个词语的词频\n",
    "    \"\"\"\n",
    "    return [Freq[w] for w in wordList]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T11:42:03.461900Z",
     "start_time": "2024-03-28T11:42:03.459937Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TF Calculation\n",
    "\n",
    "为每个句子中的单词计算对应的 在句子中的 词频 aka TF: term frequency\n",
    "\n",
    " $tf_{i,j} = \\frac{n_{i,j}}{\\sum_{k}n_{k,j}}$,\n",
    "\n",
    "i 是词语索引, j 是句子索引\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " each sentence will construct its features on the scale of the whole vocabulary list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def get_tf_feat(wordList,vocab):\n",
    "    \"\"\"\n",
    "    这个函数 根据词频构建句子的特征\n",
    "    :param wordList: 单词列表\n",
    "    :param vocab: 词汇表\n",
    "    :return: 句子的特征向量\n",
    "    \"\"\"\n",
    "    tf = np.zeros(vocab_size)\n",
    "    freq = wordFreq(wordList)\n",
    "    for item in freq.items():\n",
    "        tf[vocab.index(item[0])] = item[1]\n",
    "    tf = tf/tf.sum()\n",
    "    return tf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T11:42:03.468371Z",
     "start_time": "2024-03-28T11:42:03.463129Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "21624"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "len(vocab)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T11:42:03.468637Z",
     "start_time": "2024-03-28T11:42:03.465842Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " ## 遍历数据集 构建每个句子的tf特征"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/5000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1c740a6f098c4d2481a6def8e8dd1943"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "recordsWithTF = copy.deepcopy(recordsWithWords)\n",
    "for idx,item in enumerate(tqdm(recordsWithTF)):\n",
    "    tf = get_tf_feat(item['words'],vocab)\n",
    "    item['TF_array'] = tf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T11:42:11.446281Z",
     "start_time": "2024-03-28T11:42:03.480833Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.14285714285714285,\n 0.14285714285714285,\n 0.14285714285714285,\n 0.14285714285714285,\n 0.14285714285714285,\n 0.14285714285714285,\n 0.14285714285714285]"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item for item in recordsWithTF[42]['TF_array'].tolist() if item!=0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T11:42:11.478940Z",
     "start_time": "2024-03-28T11:42:11.449342Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "IDF Calculation\n",
    "\n",
    "$idf_i = lg\\frac{|D|}{1 + |{j:t_i \\in d_j}|}$\n",
    "\n",
    "|D|: the total of sentences\n",
    "$d_j$: the specific j-th sentence\n",
    "|{j:t_i \\in d_j}|: the number of sentences that contains the word $t_i$\n",
    "\n",
    "1+: avoid zero division when the word not in any sentences\n",
    "\n",
    "idf是针对整个数据集做的统计"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def calculateCorpusIDF(vocab,ListOfWordList):\n",
    "    IDF_values = { w:0 for idx,w in enumerate(vocab)}\n",
    "    D = len(ListOfWordList)\n",
    "    for w in tqdm(IDF_values.keys()):\n",
    "        count = 1\n",
    "        for doc in ListOfWordList:\n",
    "            if w in doc:\n",
    "                count+=1\n",
    "        idf_value = math.log(D/count)\n",
    "        IDF_values.update({w:idf_value})\n",
    "    return IDF_values\n",
    "\n",
    "\n",
    "def get_idf_feat(wordList,idf_values):\n",
    "    assert idf_values != None\n",
    "    idf = np.zeros(vocab_size)\n",
    "    for w in wordList:\n",
    "        idf[word2id[w]] = idf_values[w]\n",
    "    return idf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T11:42:11.538373Z",
     "start_time": "2024-03-28T11:42:11.468843Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/21624 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "11d93965f9ed43b0bfb14937b10a5f87"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idf_values = calculateCorpusIDF(vocab,[item['words'] for item in data_records])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T11:42:25.449005Z",
     "start_time": "2024-03-28T11:42:11.474559Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "recordsWithTFIDF = copy.deepcopy(recordsWithTF)\n",
    "for idx,r in enumerate(recordsWithTFIDF):\n",
    "    r['IDF'] = get_idf_feat(r['words'],idf_values)\n",
    "    recordsWithTFIDF[idx] = r"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T11:42:26.253281Z",
     "start_time": "2024-03-28T11:42:25.450095Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "{'id': 43,\n 'content': '有些事越想要越得不到，有些梦只能相信，是这样吗',\n 'task-1': 'neg',\n 'task-2': 'sad',\n 'words': ['事越', '想要', '越', '得不到', '梦', '只能', '相信'],\n 'TF_array': array([0., 0., 0., ..., 0., 0., 0.]),\n 'IDF': array([0., 0., 0., ..., 0., 0., 0.])}"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recordsWithTFIDF[42]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T11:42:26.257198Z",
     "start_time": "2024-03-28T11:42:26.254408Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "[7.824046010856292,\n 4.688551794927142,\n 6.725433722188183,\n 4.645992180508347,\n 4.990832666800076,\n 5.221356325411908,\n 5.115995809754082]"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item for item in recordsWithTFIDF[42]['IDF'].tolist() if item!=0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T11:42:26.260292Z",
     "start_time": "2024-03-28T11:42:26.257694Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def get_tf_idf_feat(wordList,idf_values,vocab):\n",
    "    tf = get_tf_feat(wordList,vocab)\n",
    "    idf = get_idf_feat(wordList,idf_values)\n",
    "    tf_idf = tf * idf\n",
    "    return tf_idf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T11:42:26.261875Z",
     "start_time": "2024-03-28T11:42:26.260730Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/5000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5a6414fc16c34f01b5cd3df6f49f8b2a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "recordsWithTFIDF = copy.deepcopy(recordsWithTFIDF)\n",
    "\n",
    "for idx,r in enumerate(tqdm(recordsWithTFIDF)):\n",
    "    r['TFIDF'] = get_tf_idf_feat(r['words'],idf_values,vocab)\n",
    "    recordsWithTFIDF[idx] = r"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T11:42:33.998583Z",
     "start_time": "2024-03-28T11:42:26.263098Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "{'id': 43,\n 'content': '有些事越想要越得不到，有些梦只能相信，是这样吗',\n 'task-1': 'neg',\n 'task-2': 'sad',\n 'words': ['事越', '想要', '越', '得不到', '梦', '只能', '相信'],\n 'TF_array': array([0., 0., 0., ..., 0., 0., 0.]),\n 'IDF': array([0., 0., 0., ..., 0., 0., 0.]),\n 'TFIDF': array([0., 0., 0., ..., 0., 0., 0.])}"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recordsWithTFIDF[42]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T11:42:34.002529Z",
     "start_time": "2024-03-28T11:42:34.000040Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "[1.117720858693756,\n 0.6697931135610203,\n 0.9607762460268832,\n 0.6637131686440495,\n 0.7129760952571537,\n 0.7459080464874154,\n 0.7308565442505831]"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item for item in recordsWithTFIDF[42]['TFIDF'].tolist() if item!=0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T11:42:34.005191Z",
     "start_time": "2024-03-28T11:42:34.003465Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def similarity(vec_a,vec_b):\n",
    "    \"\"\"\n",
    "    Cosine Similarity Calculation\n",
    "\n",
    "    :param vec_a: np array\n",
    "    :param vec_b: np array\n",
    "    :return: float\n",
    "    \"\"\"\n",
    "    return np.linalg.multi_dot([vec_a,vec_b]) / (np.linalg.norm(vec_a) * np.linalg.norm(vec_b))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T11:42:34.007037Z",
     "start_time": "2024-03-28T11:42:34.006179Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "tfidfs = np.array([item['TFIDF'] for item in recordsWithTFIDF])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T11:45:05.106133Z",
     "start_time": "2024-03-28T11:45:04.509511Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/5000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "75518af4015d4735862e3cae9edbdb2d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sim = np.zeros((len(tfidfs),len(tfidfs)))\n",
    "for x in tqdm(range(len(tfidfs))):\n",
    "    for y in range(len(tfidfs)):\n",
    "        sim[x,y] = similarity(tfidfs[x],tfidfs[y])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T11:43:00.689417Z",
     "start_time": "2024-03-28T11:42:34.162850Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "用pytorch加速这个计算过程 可以了解一下爱因斯坦求和公式"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([5000, 21624])"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.nn.functional.normalize(torch.tensor(tfidfs),dim=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T11:50:00.981331Z",
     "start_time": "2024-03-28T11:50:00.210331Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n       dtype=torch.float64)"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim = torch.einsum('xv,yv->xy',torch.nn.functional.normalize(torch.tensor(tfidfs),dim=-1),torch.nn.functional.normalize(torch.tensor(tfidfs),dim=-1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T11:50:45.610767Z",
     "start_time": "2024-03-28T11:50:41.838735Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "宿舍要民汉合宿了为毛都大三了还要折腾我\n",
      "这样参加个毛招聘会啊拍个毛毕业照啊\n",
      "今天要崩溃死我不可，为毛就这么倒霉！为毛办个事就这么不容易！KAO!MD!\n",
      "才睡半小时就被折腾醒宿舍暖气太给力盖被子吧热的不行不盖吧蚊子老咬人咋办\n",
      "我大三食放了剩下的盛夏！清早心情好。\n",
      "每次院校抽检别的宿舍是抽检我们宿舍就变成每月例行检查即使我们门口装饰太美！宿舍再整齐！我的贴纸你们再喜欢！！！能不能别每次都来每次都要在我那里拍照\n",
      "休息一天比上班还累，这一天可折腾死宝宝了\n",
      "我靠！拆空调的人居然可以直接进宿舍！营业厅的人接网线还得等我们进宿舍！丢东西了谁负责哦！\n",
      "折腾到现在可算是到了，饿坏了，附近既然既然没什么餐厅\n",
      "上海家化玩的是什么鬼？作为40块的股票，一天波动1毛4\n",
      "写教案，做PPT，讲课，上党校，考研，谁TM再告诉我大三好玩\n",
      "哔了狗了！都快大三下学期了来个指纹打卡！那么多天没课在学校吃屎嘛！\n",
      "第二招：拉一小点，打火机烧一下，有毛发烧胡的味道。\n",
      "“为什么心情不好的时候总会想吃东西”“因为伤心欲嚼”为毛我是开心的时候变为胃plus\n",
      "甘叼毛，天氣，好熱，搞我又冷又熱，好頭痛啊\n",
      "整天生一些有七没八的破事折腾人，天怒人怨遭雷劈！！！\n",
      "逼事真多，什么狗玩意，老子要回宿舍??????\n",
      "今天去医院建卡，从七点半折腾到十点多，抽了七管血\n",
      "我折腾一中午没睡着那几只睡得现在都还没醒说好的三点去图书馆呢\n",
      "我的脚丫好酸啊这个点回来宿舍阿姨竟然锁门\n",
      "再也没有办法像大二大三那样愉快的玩耍了每天事特多总感觉天天都好忙想着还有好多任务没完成心更累\n",
      "男朋友宿舍里养了只狗然后妈的下大雨了我现在很烦想死全湿了\n",
      "淋了一晚上雨还穿着高跟鞋来回宿舍和水房两趟…\n",
      "脑残的点了一个不改点的确定，结果折腾到现在～下手需三思，期待恢复正常使用，快见光明～\n",
      "今晚通关了逃生。人心最可怕。一个人在宿舍。有点不敢睡。以后不能一个人玩恐怖游戏。晚安。\n",
      "本人虽然长的不俊，但走到那都招人喜欢，燕过留声人过留名，从哪里离开别人都没有说我不好的。不知为毛偏偏不得现在主管待见，一天不找个事不得劲，还天天下班拖我到现在\n",
      "集体宿舍真的很不好，没人会考虑你的感受，比如在个人卫生问题上，比如在你睡觉时，别人总是在那放各种电视剧，音乐，制造各种噪音\n",
      "本来一个人坐着吃饭挺好的，非进来个情侣，来一对还不行啊还进来两对，唉，回了宿舍还是被虐，现在不想看到任何的秀恩爱\n",
      "宿舍的姑娘们都疯了，不约会了，不化妆了，不睡懒觉了，不玩手机了，竟然连饭都不吃了。一心bia在琴房练琴，提升自我逼格！！！！！！！！！！\n",
      "Day42_今天我觉得最大的幸福应该是一起学习（抄作业）到很晚哪怕再不舒服再困也都记得给我凉一杯水/细节打败爱情在你手里变成了爱情成就细节/辣火锅拉黑你就去吃药吧折腾死你算惹\n",
      "读书的时候最怕的就是自己一个好朋友跟另一个好朋友冷战，特别是大学宿舍里。天真的我以为毕业了就摆脱这个顾虑了，万万没想到，我爸跟我妈居然也来这套，而且今天已经是第七天了。简直心累到想狗带\n",
      "什么破老师啊讲课讲不明白读个东西也读不顺好像刚学会说话样这都大三了她是学院派来跟我们闹着玩的嘛真是能不能给我们换个好老师好好教我们啊让这种老师教太侮辱我们这些坐在教室里学习的同学了我实在忍不下去了必须吐槽是不是学院没老师了啊把打扫卫生的阿姨给征来当老师了啊\n",
      "虽然夜黑风高但是我不怕鬼冒死下班洗完澡拿了八个快递安全回到了宿舍我就说败家娘们败了这么多一定会有一大堆一起到货的猜准了事总是要发生的摸摸哒\n",
      "一天没回宿舍，晚上还跟人干了一仗，在零下好几度的寒夜里拖着大羽绒服来个鸟不拉屎的礼堂，竟然是要给我看爱党影片焦裕禄！？！握日，你真的不是在逗我？\n",
      "供吧还是起码西南这边得供啊坐在宿舍里和坐在山顶操场上感觉没什么区别甚至有时候屋里比外边儿还冷一件衣服都要好几天才能晾干北方狗表示很忧桑\n",
      "我是个奇怪的人。冷漠让人厌恶，热情让人害怕。冷面冷心或许更适合我。怜悯不再，慈悲心也越发的没了。遇到了像某个时期被自己厌恶的我，在靠近中越来越不和，聊心，吵架。各种折腾，后归于平静。又发现了一个像某个时期让自己心疼的我，于是不自觉的就贴上去了，好像吓着别人了。所以就该冷漠到底嘛～\n",
      "昨天到了布拉格20.00多，晚了差不多两个小时，因为上次很晚回宿舍被一群地痞吓到过，这次也是心有余悸，不过这里还好，旅游的人很多，虽然天很黑了，也没那么让人感觉害怕。Thuy姐一直在等我们，好温柔啊，善良的姐姐。开门的时候问我，上次来是和你男朋友么？我说，不是，是和我女朋友。。。。。女...全文\n",
      "闭着眼睛，突然眼泪又掉了下来??在我拿不动很重的被子的时候，你在睡觉，在我肚子痛的要命的时候，你说你有事，在我迷路的时候，你…我不知道你在干嘛，在我伤心难过在宿舍外面吹着冷风的时候，你恐怕还在和家人说着我的坏话吧，然后安心的睡觉，然后理所应当的觉得你受了委屈！这些都是很深的疤\n",
      "听说学校附近开了家辣凤芹，于是全宿舍和同学满心欢喜的一起订了九份，九份！然后，按说好的时间去新大正门拿，人家说在新大附中，呵呵，跑到新大附中，人家说米粉没了，好歹我们九份也是大客户吧\n",
      "欣欣欣欣生日快乐！宝宝才到宿舍！唉遥想当年我们那么浪漫在小黑屋里你给笨宝宝唱歌听！陪本宝宝打牌玩！小姨小姨我爱你我爱你我爱你我爱你！秒拍啊小视频等我有手机再拍给你！！！！！！！！！！\n",
      "原来介玩意是叫草子糕啊！我活了30多年一直以为是槽子糕了！涨姿势了！\n",
      "做完饭不洗锅，什么都往水池扔，什么都往厕所倒，所以三天两头都是堵，不讲卫生也就罢了，天天带男人回家，带男人回家也就罢了，天天摔桌子吵架，嗓门大如泼妇，堪比河东狮吼，二房东这是招的什么人\n",
      "啥破事都赶一块了又不是我不想去那个单词复赛\n",
      "死老头你要是早出现两个月我也不至于这两年每月都要往牡丹江跑受罪了\n",
      "明太祖洪武十年（1377年），改变圜丘礼制，定每年孟春正月合祀天地于南郊，建大祀殿，以圜形大屋覆盖祭坛。\n",
      "昨晚得知，yaba竟把牙的阴历生日给忘了，先是说不出，后又蒙出个初10，还信誓旦旦的说，对就初十。Kou,YND\n",
      "讨厌极了这种焦虑感，睡眠质量最近都差了好多…\n",
      "真的挺不舒服的…比我想象的要难受得多\n",
      "我觉得在地铁里蹭别人的电视剧看，而且还笑的那么夸张的人简直太可爱了。噗哈哈哈\n",
      "11-15一个镜头也没有！没有！\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2983, 0.2276, 0.1851, 0.1776, 0.1758, 0.1657, 0.1648, 0.1573,\n",
      "        0.1438, 0.1405, 0.1354, 0.1309, 0.1292, 0.1252, 0.1245, 0.1240, 0.1239,\n",
      "        0.1236, 0.1182, 0.1177, 0.1100, 0.1040, 0.0997, 0.0989, 0.0909, 0.0840,\n",
      "        0.0764, 0.0734, 0.0680, 0.0680, 0.0667, 0.0664, 0.0656, 0.0638, 0.0632,\n",
      "        0.0574, 0.0572, 0.0495, 0.0464, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000], dtype=torch.float64),\n",
      "indices=tensor([   0, 2138, 3998, 4063, 2890, 1228, 4484, 1085, 4122,  349, 3087, 1466,\n",
      "        3989, 1195,  123, 2923,   71,  247, 2659, 1860, 3522,  376, 4153, 4393,\n",
      "        4516,  887, 3602, 3956, 2047,  725, 3051, 2643, 3587, 4024, 1168,  177,\n",
      "        3812, 1534, 2246, 4832,   30,   14,   29,   28,    6,   13,   27,   26,\n",
      "          12,   25]))\n"
     ]
    }
   ],
   "source": [
    "inspect_id = 0\n",
    "k = 50\n",
    "indices = torch.topk(sim[inspect_id],k=k).indices.tolist()\n",
    "\n",
    "for idx in indices:\n",
    "    print(recordsWithTFIDF[idx]['content'])\n",
    "print(torch.topk(sim[inspect_id],k=k))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T11:59:57.071250Z",
     "start_time": "2024-03-28T11:59:57.068738Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
